{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the combined file\n",
    "loaded_model = joblib.load('models/kmeans_with_preprocessor.joblib')\n",
    "\n",
    "# Access the KMeans model and preprocessor\n",
    "kmeans_loaded = loaded_model['kmeans']\n",
    "preprocessor = loaded_model['preprocessor']\n",
    "\n",
    "df = pd.read_csv('csv/df_merged_cleaned.csv')\n",
    "\n",
    "\n",
    "# Define features to include in clustering\n",
    "features = ['rating', 'reviews', 'size', 'installs', 'price', 'average_sentiment_analysis', 'average_sentiment_subjectivity']\n",
    "\n",
    "# Create a feature matrix\n",
    "X = df[features].copy()\n",
    "\n",
    "# Separate features into numerical for preprocessing\n",
    "numerical_features = ['rating', 'reviews', 'size', 'installs', 'price', 'average_sentiment_analysis', 'average_sentiment_subjectivity']\n",
    "\n",
    "# Define preprocessing for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Impute missing values with the median\n",
    "    ('scaler', StandardScaler())  # Normalize features\n",
    "])\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>size</th>\n",
       "      <th>installs</th>\n",
       "      <th>price</th>\n",
       "      <th>average_sentiment_analysis</th>\n",
       "      <th>average_sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.10</td>\n",
       "      <td>159.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.90</td>\n",
       "      <td>967.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.70</td>\n",
       "      <td>87510.00</td>\n",
       "      <td>8.70</td>\n",
       "      <td>5000000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.50</td>\n",
       "      <td>215644.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>50000000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.30</td>\n",
       "      <td>967.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>100000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9634</th>\n",
       "      <td>4.50</td>\n",
       "      <td>38.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9635</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9636</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9637</th>\n",
       "      <td>4.50</td>\n",
       "      <td>114.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9638</th>\n",
       "      <td>4.50</td>\n",
       "      <td>398307.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>10000000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9639 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating   reviews  size    installs  price  average_sentiment_analysis  \\\n",
       "0       4.10    159.00 19.00    10000.00   0.00                         NaN   \n",
       "1       3.90    967.00 14.00   500000.00   0.00                        0.15   \n",
       "2       4.70  87510.00  8.70  5000000.00   0.00                         NaN   \n",
       "3       4.50 215644.00 25.00 50000000.00   0.00                         NaN   \n",
       "4       4.30    967.00  2.80   100000.00   0.00                         NaN   \n",
       "...      ...       ...   ...         ...    ...                         ...   \n",
       "9634    4.50     38.00 53.00     5000.00   0.00                         NaN   \n",
       "9635    5.00      4.00  3.60      100.00   0.00                         NaN   \n",
       "9636     NaN      3.00  9.50     1000.00   0.00                         NaN   \n",
       "9637    4.50    114.00   NaN     1000.00   0.00                         NaN   \n",
       "9638    4.50 398307.00 19.00 10000000.00   0.00                         NaN   \n",
       "\n",
       "      average_sentiment_subjectivity  \n",
       "0                                NaN  \n",
       "1                               0.64  \n",
       "2                                NaN  \n",
       "3                                NaN  \n",
       "4                                NaN  \n",
       "...                              ...  \n",
       "9634                             NaN  \n",
       "9635                             NaN  \n",
       "9636                             NaN  \n",
       "9637                             NaN  \n",
       "9638                             NaN  \n",
       "\n",
       "[9639 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.82063048e-01, -1.18067702e-01, -4.36020071e-02, ...,\n",
       "        -6.36713577e-02, -4.14378590e-03,  1.74407762e-02],\n",
       "       [-5.67587152e-01, -1.17626767e-01, -2.89993454e-01, ...,\n",
       "        -6.36713577e-02, -9.74828532e-01,  5.83909959e+00],\n",
       "       [ 9.74509263e-01, -7.03992754e-02, -5.51168387e-01, ...,\n",
       "        -6.36713577e-02, -4.14378590e-03,  1.74407762e-02],\n",
       "       ...,\n",
       "       [ 2.03461056e-01, -1.18152833e-01, -5.11745756e-01, ...,\n",
       "        -6.36713577e-02, -4.14378590e-03,  1.74407762e-02],\n",
       "       [ 5.88985159e-01, -1.18092259e-01, -3.39271743e-01, ...,\n",
       "        -6.36713577e-02, -4.14378590e-03,  1.74407762e-02],\n",
       "       [ 5.88985159e-01,  9.92061558e-02, -4.36020071e-02, ...,\n",
       "        -6.36713577e-02, -4.14378590e-03,  1.74407762e-02]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "##this is the function\n",
    "def find_similar_apps(app_name, df, X_processed, n_similar=5):\n",
    "    # Check if the app_name exists\n",
    "    if app_name not in df['app'].values:\n",
    "        return f\"App '{app_name}' not found in the dataset.\"\n",
    "    \n",
    "    # Find the app's index\n",
    "    app_index = df[df['app'] == app_name].index[0]\n",
    "    \n",
    "    # Get the app's feature vector\n",
    "    app_vector = X_processed[app_index].reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity between the app and all other apps\n",
    "    similarities = cosine_similarity(app_vector, X_processed).flatten()\n",
    "    \n",
    "    # Get indices of the most similar apps\n",
    "    similar_indices = similarities.argsort()[-(n_similar + 1):-1]\n",
    "    \n",
    "    # Exclude the app itself\n",
    "    similar_apps = df.iloc[similar_indices]\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    aggregation = similar_apps[['rating', 'reviews', 'size', 'installs', 'price']].agg(['mean', 'std'])\n",
    "    \n",
    "    return similar_apps[['app', 'rating', 'reviews', 'size', 'installs', 'price']], aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "##this is the function\n",
    "# def find_similar_apps(app_name, df, X_processed, n_similar=5):\n",
    "#     # Check if the app_name exists\n",
    "#     if app_name not in df['app'].values:\n",
    "#         return f\"App '{app_name}' not found in the dataset.\"\n",
    "    \n",
    "    # Find the app's index\n",
    "n_similar = 5\n",
    "\n",
    "app_index = df[df['app'] == \"facebook\"].index[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2002)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating                                    4.10\n",
       "reviews                            78158306.00\n",
       "size                                       NaN\n",
       "installs                         1000000000.00\n",
       "price                                     0.00\n",
       "average_sentiment_analysis               -0.01\n",
       "average_sentiment_subjectivity            0.46\n",
       "Name: 2002, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the app's feature vector\n",
    "app_vector = X.iloc[app_index]\n",
    "app_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp_vector\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:968\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m    966\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:536\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    534\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    535\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 536\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_indexing.py:330\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_interchange_protocol(X):\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_column_indices_interchange(X\u001b[38;5;241m.\u001b[39m__dataframe__(), key, key_dtype)\n\u001b[0;32m--> 330\u001b[0m n_columns \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;66;03m# we get an empty list\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "processed = preprocessor.fit_transform(app_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate cosine similarity between the app and all other apps\n",
    "similarities = cosine_similarity(app_vector, X_processed).flatten()\n",
    "\n",
    "# Get indices of the most similar apps\n",
    "similar_indices = similarities.argsort()[-(n_similar + 1):-1]\n",
    "\n",
    "# Exclude the app itself\n",
    "similar_apps = df.iloc[similar_indices]\n",
    "\n",
    "# Aggregate statistics\n",
    "aggregation = similar_apps[['rating', 'reviews', 'size', 'installs', 'price']].agg(['mean', 'std'])\n",
    "\n",
    "\n",
    "    \n",
    "    # return similar_apps[['app', 'rating', 'reviews', 'size', 'installs', 'price']], aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapp_index\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'app_index' is not defined"
     ]
    }
   ],
   "source": [
    "app_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Find the app's index\n",
    "    app_index = df[df['app'] == app_name].index[0]\n",
    "    \n",
    "    # Get the app's feature vector\n",
    "    app_vector = X_processed[app_index].reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity between the app and all other apps\n",
    "    similarities = cosine_similarity(app_vector, X_processed).flatten()\n",
    "    \n",
    "    # Get indices of the most similar apps\n",
    "    similar_indices = similarities.argsort()[-(n_similar + 1):-1]\n",
    "    \n",
    "    # Exclude the app itself\n",
    "    similar_apps = df.iloc[similar_indices]\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    aggregation = similar_apps[['rating', 'reviews', 'size', 'installs', 'price']].agg(['mean', 'std'])\n",
    "    \n",
    "    return similar_apps[['app', 'rating', 'reviews', 'size', 'installs', 'price']], aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_apps, aggregation = find_similar_apps('facebook', df, X_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>size</th>\n",
       "      <th>installs</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>retrica</td>\n",
       "      <td>4.30</td>\n",
       "      <td>6120977.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000000.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>messenger_â€“_text_and_video_chat_for_free</td>\n",
       "      <td>4.00</td>\n",
       "      <td>56642847.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000000.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>instagram</td>\n",
       "      <td>4.50</td>\n",
       "      <td>66577313.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000000.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>clean_master-_space_cleaner_&amp;_antivirus</td>\n",
       "      <td>4.70</td>\n",
       "      <td>42916526.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000000.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>whatsapp_messenger</td>\n",
       "      <td>4.40</td>\n",
       "      <td>69119316.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000000.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           app  rating     reviews  size  \\\n",
       "2276                                   retrica    4.30  6120977.00   NaN   \n",
       "299   messenger_â€“_text_and_video_chat_for_free    4.00 56642847.00   NaN   \n",
       "2003                                 instagram    4.50 66577313.00   NaN   \n",
       "3179   clean_master-_space_cleaner_&_antivirus    4.70 42916526.00   NaN   \n",
       "300                         whatsapp_messenger    4.40 69119316.00   NaN   \n",
       "\n",
       "          installs  price  \n",
       "2276  100000000.00   0.00  \n",
       "299  1000000000.00   0.00  \n",
       "2003 1000000000.00   0.00  \n",
       "3179  500000000.00   0.00  \n",
       "300  1000000000.00   0.00  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>size</th>\n",
       "      <th>installs</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.38</td>\n",
       "      <td>48275395.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>720000000.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.26</td>\n",
       "      <td>25715539.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408656334.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating     reviews  size     installs  price\n",
       "mean    4.38 48275395.80   NaN 720000000.00   0.00\n",
       "std     0.26 25715539.72   NaN 408656334.83   0.00"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_apps(user_input_vector, n_similar=5):\n",
    "    # Import necessary libraries\n",
    "    import joblib\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Define relative paths\n",
    "    model_path = Path('models/kmeans_with_preprocessor.joblib')\n",
    "    csv_path = Path('csv/df_merged_cleaned.csv')\n",
    "    \n",
    "    # Load the pre-trained model and preprocessor\n",
    "    loaded_model = joblib.load(model_path)\n",
    "    preprocessor = loaded_model['preprocessor']\n",
    "\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Define features to include in clustering\n",
    "    features = ['rating', 'reviews', 'size', 'installs', 'price', 'average_sentiment_analysis', 'average_sentiment_subjectivity']\n",
    "    \n",
    "    # Create a feature matrix and apply preprocessing\n",
    "    X = df[features].copy()\n",
    "    X_processed = preprocessor.transform(X)\n",
    "\n",
    "    user_input_df = pd.DataFrame(user_input_vector, columns=features)\n",
    "    user_input_vector = preprocessor.transform(user_input_vector)\n",
    "    # Convert the list to a numpy array and reshape it to match the expected input format\n",
    "    app_vector = np.array(user_input_vector).reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity and get indices of the most similar apps\n",
    "    similarities = cosine_similarity(app_vector, X_processed).flatten()\n",
    "    similar_indices = similarities.argsort()[-(n_similar + 1):-1]\n",
    "    \n",
    "    # Exclude the app itself and aggregate statistics\n",
    "    similar_apps = df.iloc[similar_indices]\n",
    "    aggregation = similar_apps[['rating', 'reviews', 'size', 'installs', 'price']].agg(['mean', 'std'])\n",
    "    \n",
    "    # Return similar apps and aggregated statistics\n",
    "    return similar_apps[['app', 'rating', 'reviews', 'size', 'installs', 'price']], aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[{'rating': 4.1, 'reviews': 190, 'size': 24, 'installs': 10500, 'price': 1.79, 'average_sentiment_analysis': 0.25, 'average_sentiment_subjectivity': 0.15}].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m user_input_vector \u001b[38;5;241m=\u001b[39m [{\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4.1\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviews\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m190\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_sentiment_subjectivity\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.15\u001b[39m\n\u001b[1;32m     10\u001b[0m }]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Test the function\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m similar_apps, aggregation \u001b[38;5;241m=\u001b[39m \u001b[43mfind_similar_apps\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilar Apps:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(similar_apps)\n",
      "Cell \u001b[0;32mIn[106], line 26\u001b[0m, in \u001b[0;36mfind_similar_apps\u001b[0;34m(user_input_vector, n_similar)\u001b[0m\n\u001b[1;32m     23\u001b[0m X \u001b[38;5;241m=\u001b[39m df[features]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     24\u001b[0m X_processed \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m---> 26\u001b[0m user_input_vector \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Convert the list to a numpy array and reshape it to match the expected input format\u001b[39;00m\n\u001b[1;32m     28\u001b[0m app_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(user_input_vector)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1036\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m   1034\u001b[0m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1035\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1036\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m# If ColumnTransformer is fit using a dataframe, and now a dataframe is\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# passed to be transformed, we select columns by name instead. This\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# enables the user to pass X at transform time with extra columns which\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# were not present in fit time, and the order of the columns doesn't\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# matter.\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m fit_dataframe_and_transform_dataframe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   1044\u001b[0m     _is_pandas_df(X) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataframe__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1045\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1299\u001b[0m, in \u001b[0;36m_check_X\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dataframe__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n\u001b[0;32m-> 1299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m             )\n\u001b[0;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[{'rating': 4.1, 'reviews': 190, 'size': 24, 'installs': 10500, 'price': 1.79, 'average_sentiment_analysis': 0.25, 'average_sentiment_subjectivity': 0.15}].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Define a sample user input vector\n",
    "user_input_vector = [{\n",
    "    'rating': 4.1,\n",
    "    'reviews': 190,\n",
    "    'size': 24,\n",
    "    'installs': 10500,\n",
    "    'price': 1.79,\n",
    "    'average_sentiment_analysis': 0.25,\n",
    "    'average_sentiment_subjectivity': 0.15\n",
    "}]\n",
    "\n",
    "# Test the function\n",
    "similar_apps, aggregation = find_similar_apps(user_input_vector)\n",
    "\n",
    "print(\"Similar Apps:\")\n",
    "print(similar_apps)\n",
    "\n",
    "print(\"\\nAggregation:\")\n",
    "print(aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    object\n",
       "1    object\n",
       "2    object\n",
       "3    object\n",
       "4    object\n",
       "5    object\n",
       "6    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
